import { AppError, ErrorCode } from '../types';
import RNFS from 'react-native-fs';
import ConfigService from './ConfigService';
import { Platform } from 'react-native';
import { AZURE_SPEECH_KEY, AZURE_SPEECH_REGION } from '@env';

export class SpeechService {

  private getAzureCredentials() {
    // 1. å°è¯•ä»é…ç½®æœåŠ¡è·å–
    let apiKey = ConfigService.getApiKey('azureSpeech');
    let region = ConfigService.get('api').azureSpeechRegion;

    // 2. å¦‚æœé…ç½®ä¸ºç©ºï¼Œå›é€€åˆ°ç¯å¢ƒå˜é‡
    if (!apiKey) apiKey = AZURE_SPEECH_KEY;
    // å¦‚æœ region ä¸ºç©ºæˆ–è€…ä¾ç„¶æ˜¯æ—§é»˜è®¤å€¼(eastus)ä½†envé‡Œæ˜¯æ–°çš„ï¼Œä¼˜å…ˆç”¨Env
    if (!region || (region === 'eastus' && AZURE_SPEECH_REGION)) {
        region = AZURE_SPEECH_REGION || 'westus2';
    }

    // é»˜è®¤å…œåº•
    if (!region) region = 'westus2';

    console.log(`ğŸ”‘ Azure Auth Check: Region=[${region}] KeyLength=[${apiKey ? apiKey.length : 0}]`);

    if (!apiKey || apiKey.trim() === '') {
      throw new AppError(
        ErrorCode.CONFIGURATION_ERROR,
        'Azure Speech Key æœªé…ç½®ï¼Œæ— æ³•ä½¿ç”¨è¯­éŸ³æœåŠ¡'
      );
    }
    return { apiKey, region };
  }

  /**
   * è¯­éŸ³è½¬æ–‡å­— (Azure STT REST API)
   * æ³¨æ„: Azure REST API ä»…æ”¯æŒ WAV/OGG æ ¼å¼
   */
  async speechToText(audioPath: string): Promise<string> {
    try {
      console.log('ğŸ™ï¸ STT Requesting (Azure):', audioPath);
      const { apiKey, region } = this.getAzureCredentials();

      // ä¼˜åŒ–æ–‡ä»¶è¯»å–: ç›´æ¥é€šè¿‡ fetch è¯»å–æœ¬åœ°æ–‡ä»¶ä¸º Blob
      // è¿™æ¯” base64 -> blob è½¬æ¢æ›´é«˜æ•ˆä¸”å…¼å®¹æ€§æ›´å¥½
      const fileResponse = await fetch(`file://${audioPath}`);
      const blob = await fileResponse.blob();

      const url = `https://${region}.stt.speech.microsoft.com/speech/recognition/conversation/cognitiveservices/v1?language=zh-CN`;

      const response = await fetch(url, {
        method: 'POST',
        headers: {
          'Ocp-Apim-Subscription-Key': apiKey,
          'Content-Type': 'audio/wav; codecs=audio/pcm; samplerate=16000',
          'Accept': 'application/json',
        },
        body: blob as any, // React Native fetch supports Blob
      });

      if (!response.ok) {
        const text = await response.text();
        console.error('âŒ Azure STT Error:', response.status, text);

        if (response.status === 400) {
           throw new Error('Azure STT æ ¼å¼é”™è¯¯ (è¯·ç¡®ä¿å½•éŸ³ä¸ºWAVæ ¼å¼)');
        }
        throw new Error(`Azure STT å¤±è´¥ (${response.status})`);
      }

      const data = await response.json();
      console.log('âœ… Azure STT Result:', data);

      if (data.RecognitionStatus === 'Success') {
        return data.DisplayText;
      } else {
        console.warn('Azure STT No Match:', data.RecognitionStatus);
        return '';
      }

    } catch (error: any) {
      console.error('STT Exception:', error);
      throw error;
    }
  }

  /**
   * æ–‡å­—è½¬è¯­éŸ³ (Azure TTS REST API)
   * @param text è¦åˆæˆçš„æ–‡æœ¬
   * @param options åˆæˆé€‰é¡¹
   */
  async textToSpeech(
    text: string,
    options: {
      voiceId?: string;
      style?: string; // chat, cheerful, sad, etc.
      speed?: number; // 0.5 - 2.0
      pitch?: string; // default, high, low
    } = {}
  ): Promise<string> {
    try {
      const {
        voiceId = 'zh-CN-XiaoxiaoNeural',
        style = 'chat',
        speed = 1.0,
        pitch = 'default'
      } = options;

      console.log(`ğŸ—£ï¸ TTS Requesting (Azure): [${voiceId}] ${text.substring(0, 20)}...`);
      const { apiKey, region } = this.getAzureCredentials();

      const fileName = `tts_${Date.now()}.mp3`;
      const destPath = `${RNFS.DocumentDirectoryPath}/${fileName}`;

      // è¯­é€Ÿè½¬æ¢
      const ratePct = Math.round((speed - 1.0) * 100);
      const rateStr = ratePct >= 0 ? `+${ratePct}%` : `${ratePct}%`;

      // æŸäº›è¯­éŸ³å¯èƒ½ä¸æ”¯æŒ styleï¼Œç®€å•åˆ—è¡¨åˆ¤æ–­ï¼ˆå®é™…åº”ä» API è·å–ï¼‰
      // æ™“æ™“ã€äº‘å¸Œç­‰é€šå¸¸æ”¯æŒ styleï¼Œä½†ä¸ºäº†ç¨³å¥ï¼Œå¦‚æœ style ä¸º 'chat' ä¸”æ˜¯é»˜è®¤æƒ…å†µï¼Œå¯ä»¥ç®€åŒ– SSML

      const ssmlContent = `
        <prosody rate="${rateStr}" pitch="${pitch}">
          ${text}
        </prosody>
      `;

      // åªæœ‰åœ¨æ˜ç¡®æŒ‡å®šäº†éé»˜è®¤ style æ—¶æ‰åŒ…è£¹ express-as
      // ä¸”åªå¯¹æ”¯æŒçš„ä¸­æ–‡è¯­éŸ³æ·»åŠ 
      const supportsStyle = ['zh-CN-XiaoxiaoNeural', 'zh-CN-YunxiNeural', 'zh-CN-XiaoyiNeural', 'zh-CN-YunyangNeural', 'zh-CN-XiaomengNeural', 'zh-CN-YunjianNeural'].includes(voiceId);

      let innerSSML = ssmlContent;
      if (supportsStyle && style && style !== 'default') {
          innerSSML = `
            <mstts:express-as style="${style}">
              ${ssmlContent}
            </mstts:express-as>
          `;
      }

      // æ„å»ºå®Œæ•´ SSML çš„è¾…åŠ©å‡½æ•°
      const buildSSML = (targetVoiceId: string, useStyle: boolean, useProsody: boolean = true) => {
        let content = text;

        // 1. åŒ…è£¹è¯­é€Ÿ/éŸ³è°ƒ (Prosody)
        if (useProsody) {
          content = `
            <prosody rate="${rateStr}" pitch="${pitch}">
              ${content}
            </prosody>
          `;
        }

        // 2. åŒ…è£¹æƒ…æ„Ÿé£æ ¼ (Style)
        // åªæœ‰åœ¨æ˜ç¡®æŒ‡å®šäº†éé»˜è®¤ styleï¼Œä¸”æ”¯æŒ styleï¼Œä¸”å½“å‰å°è¯•å¯ç”¨ style æ—¶æ‰åŒ…è£¹
        if (useStyle && supportsStyle && style && style !== 'default') {
          content = `
            <mstts:express-as style="${style}">
              ${content}
            </mstts:express-as>
          `;
        }

        // 3. æ„å»º Speak/Voice æ ‡ç­¾
        // ç§»é™¤ xml:gender é¿å…ä¸ voiceId æ€§åˆ«ä¸ç¬¦å¯¼è‡´çš„é—®é¢˜
        return `
          <speak version='1.0' xml:lang='zh-CN' xmlns:mstts='https://www.w3.org/2001/mstts'>
            <voice xml:lang='zh-CN' name='${targetVoiceId}'>
              ${content}
            </voice>
          </speak>
        `;
      };

      const url = `https://${region}.tts.speech.microsoft.com/cognitiveservices/v1`;
      console.log(`ğŸ“¡ TTS URL: ${url}`); // è°ƒè¯•æ—¥å¿—ï¼šç¡®è®¤ URL

      // é€šç”¨è¯·æ±‚å‡½æ•° (ä¿®å¤ï¼šä½¿ç”¨ fetch æ›¿ä»£ RNFS.downloadFile ä»¥æ”¯æŒ POST å’Œ Body)
      const doTTSRequest = async (ssmlBody: string): Promise<number> => {
        try {
          const response = await fetch(url, {
            method: 'POST',
            headers: {
              'Ocp-Apim-Subscription-Key': apiKey,
              'X-Microsoft-OutputFormat': 'audio-16khz-128kbitrate-mono-mp3',
              'Content-Type': 'application/ssml+xml; charset=utf-8',
              'User-Agent': 'VirtualHumanApp'
            },
            body: ssmlBody,
          });

          if (!response.ok) {
            console.error('TTS Fetch Error:', response.status, await response.text());
            return response.status;
          }

          // è·å–äºŒè¿›åˆ¶æ•°æ®å¹¶å†™å…¥æ–‡ä»¶
          const blob = await response.blob();

          return new Promise((resolve) => {
            const reader = new FileReader();
            reader.onloadend = async () => {
              if (typeof reader.result === 'string') {
                // reader.result æ ¼å¼ä¸º "data:application/octet-stream;base64,....."
                const base64data = reader.result.split(',')[1];
                await RNFS.writeFile(destPath, base64data, 'base64');
                resolve(200);
              } else {
                resolve(500);
              }
            };
            reader.onerror = () => {
              console.error('Blob read error');
              resolve(500);
            };
            reader.readAsDataURL(blob);
          });

        } catch (err) {
          console.error('TTS Network Error:', err);
          return 500;
        }
      };

      // --- å°è¯•ç­–ç•¥ ---

      // ä¼˜åŒ–ï¼šå¦‚æœ prosody æ˜¯é»˜è®¤å€¼ï¼Œä¸è¦åŒ…è£¹æ ‡ç­¾ï¼Œå‡å°‘å‡ºé”™æ¦‚ç‡
      const useProsody = pitch !== 'default' || Math.abs(speed - 1.0) > 0.01;

      // 1. å®Œæ•´å°è¯•
      let statusCode = await doTTSRequest(buildSSML(voiceId, true, useProsody));

      // 2. å¤±è´¥é‡è¯• A: å¯èƒ½æ˜¯é£æ ¼(Style)ä¸æ”¯æŒ -> å»é™¤é£æ ¼ï¼Œä¿ç•™è¯­é€Ÿ
      if ((statusCode === 400 || statusCode === 404) && style && style !== 'default') {
        console.warn(`âš ï¸ Azure TTS Style '${style}' failed. Retrying without style...`);
        statusCode = await doTTSRequest(buildSSML(voiceId, false));
      }

      // 3. å¤±è´¥é‡è¯• B: å¯èƒ½æ˜¯è¯¥ VoiceId åœ¨è¯¥åŒºåŸŸä¸å¯ç”¨ -> å°è¯•ä½¿ç”¨"æ™“æ™“"ä½œä¸ºå…œåº• (Safety Voice)
      // åªæœ‰å½“å½“å‰ voiceId ä¸æ˜¯æ™“æ™“æ—¶æ‰é‡è¯•ï¼Œé¿å…æ­»å¾ªç¯
      const safetyVoice = 'zh-CN-XiaoxiaoNeural';
      if ((statusCode === 400 || statusCode === 404) && voiceId !== safetyVoice) {
        console.warn(`âš ï¸ Azure TTS Voice '${voiceId}' failed. Fallback to '${safetyVoice}'...`);
        statusCode = await doTTSRequest(buildSSML(safetyVoice, false));
      }

      if (statusCode !== 200) {
        console.error('âŒ Azure TTS Final Failure:', statusCode);
        // å°è¯•è¯»å–é”™è¯¯æ–‡ä»¶å†…å®¹ï¼ˆRNFS downloadFile 404 æ—¶ï¼Œé”™è¯¯ä¿¡æ¯å¯èƒ½åœ¨æ–‡ä»¶ä¸­ï¼‰
        try {
            const errContent = await RNFS.readFile(destPath, 'utf8');
            console.log('ğŸ“„ Error Response Body:', errContent);
        } catch (e) { /* ignore */ }

        throw new Error(`Azure TTS å¤±è´¥ (${statusCode})`);
      }

      console.log('âœ… Azure TTS Saved to:', destPath);
      return destPath;

    } catch (error) {
      console.error('TTS Exception:', error);
      throw error;
    }
  }
}

export default new SpeechService();