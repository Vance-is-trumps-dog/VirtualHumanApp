/**
 * èŠå¤©é¡µé¢ï¼ˆæ›´æ–°ç‰ˆ - æ”¯æŒè¯­éŸ³æ¨¡å¼åˆ‡æ¢ï¼‰
 */

import React, { useEffect, useState, useRef } from 'react';
import {
  View,
  FlatList,
  TextInput,
  TouchableOpacity,
  StyleSheet,
  SafeAreaView,
  KeyboardAvoidingView,
  Platform,
  Text,
  Alert,
} from 'react-native';
import { RouteProp } from '@react-navigation/native';
import { StackNavigationProp } from '@react-navigation/stack';
import { RootStackParamList } from '@navigation/RootNavigator';
import { useChatStore, useVirtualHumanStore, useSettingsStore } from '@store';
import { MessageBubble, Loading, VoiceButton, AudioPlayer } from '@components';
import { Colors, Spacing, FontSizes, BorderRadius } from '@constants';
import SpeechService from '@services/SpeechService';

type ChatScreenRouteProp = RouteProp<RootStackParamList, 'Chat'>;
type ChatScreenNavigationProp = StackNavigationProp<RootStackParamList, 'Chat'>;

interface ChatScreenProps {
  route: ChatScreenRouteProp;
  navigation: ChatScreenNavigationProp;
}

type ChatMode = 'text' | 'voice';

export const ChatScreen: React.FC<ChatScreenProps> = ({ route, navigation }) => {
  const { virtualHumanId } = route.params;
  const { messages, loading, typing, loadMessages, sendMessage } = useChatStore();
  const { currentVirtualHuman, setCurrentVirtualHuman } = useVirtualHumanStore();
  const { autoPlay, voiceSpeed } = useSettingsStore();

  const [inputText, setInputText] = useState('');
  const [mode, setMode] = useState<ChatMode>('text');
  const flatListRef = useRef<FlatList>(null);

  useEffect(() => {
    setCurrentVirtualHuman(virtualHumanId);
    loadMessages(virtualHumanId);
  }, [virtualHumanId]);

  useEffect(() => {
    // è®¾ç½®å¯¼èˆªæ ‡é¢˜
    if (currentVirtualHuman) {
      navigation.setOptions({
        title: currentVirtualHuman.name,
        headerRight: () => (
          <TouchableOpacity
            style={styles.modeButton}
            onPress={() => setMode(m => (m === 'text' ? 'voice' : 'text'))}
          >
            <Text style={styles.modeButtonText}>
              {mode === 'text' ? 'ğŸ¤' : 'âŒ¨ï¸'}
            </Text>
          </TouchableOpacity>
        ),
      });
    }
  }, [currentVirtualHuman, mode]);

  useEffect(() => {
    // æ»šåŠ¨åˆ°åº•éƒ¨
    if (messages.length > 0) {
      setTimeout(() => {
        flatListRef.current?.scrollToEnd({ animated: true });
      }, 100);
    }
  }, [messages]);

  // è‡ªåŠ¨æ’­æ”¾AIå›å¤çš„è¯­éŸ³
  useEffect(() => {
    const lastMessage = messages[messages.length - 1];
    if (
      lastMessage &&
      lastMessage.role === 'assistant' &&
      lastMessage.mode === 'voice' &&
      lastMessage.audioUrl &&
      autoPlay
    ) {
      // å»¶è¿Ÿä¸€ä¸‹å†æ’­æ”¾
      setTimeout(() => {
        playAudio(lastMessage.audioUrl!);
      }, 500);
    }
  }, [messages]);

  const playAudio = async (audioUrl: string) => {
    try {
      // è¿™é‡Œå¯ä»¥é›†æˆAudioPlayerç»„ä»¶çš„æ’­æ”¾é€»è¾‘
      console.log('Auto playing audio:', audioUrl);
    } catch (error) {
      console.error('Auto play failed:', error);
    }
  };

  const handleSendText = async () => {
    const text = inputText.trim();
    if (!text || typing) {
      return;
    }

    setInputText('');

    try {
      await sendMessage(virtualHumanId, text, mode);

      // å¦‚æœæ˜¯è¯­éŸ³æ¨¡å¼ï¼Œç”ŸæˆAIå›å¤çš„è¯­éŸ³
      if (mode === 'voice' && currentVirtualHuman) {
        const lastMessage = messages[messages.length - 1];
        if (lastMessage && lastMessage.role === 'assistant') {
          // å¼‚æ­¥ç”Ÿæˆè¯­éŸ³ï¼Œä¸é˜»å¡
          SpeechService.textToSpeech(
            lastMessage.content,
            currentVirtualHuman.voiceId,
            voiceSpeed
          ).catch(err => console.error('TTS failed:', err));
        }
      }
    } catch (error) {
      Alert.alert('é”™è¯¯', 'å‘é€å¤±è´¥ï¼Œè¯·é‡è¯•');
    }
  };

  const handleVoiceTranscript = async (text: string) => {
    try {
      await sendMessage(virtualHumanId, text, 'voice');
    } catch (error) {
      Alert.alert('é”™è¯¯', 'å‘é€å¤±è´¥ï¼Œè¯·é‡è¯•');
    }
  };

  if (loading && messages.length === 0) {
    return <Loading fullScreen message="åŠ è½½èŠå¤©è®°å½•..." />;
  }

  return (
    <SafeAreaView style={styles.container}>
      <KeyboardAvoidingView
        style={styles.keyboardView}
        behavior={Platform.OS === 'ios' ? 'padding' : undefined}
        keyboardVerticalOffset={Platform.OS === 'ios' ? 90 : 0}
      >
        {/* æ¶ˆæ¯åˆ—è¡¨ */}
        <FlatList
          ref={flatListRef}
          data={messages}
          keyExtractor={item => item.id}
          renderItem={({ item }) => (
            <View>
              <MessageBubble message={item} />
              {/* å¦‚æœæ¶ˆæ¯æœ‰éŸ³é¢‘ï¼Œæ˜¾ç¤ºæ’­æ”¾å™¨ */}
              {item.audioUrl && (
                <View
                  style={[
                    styles.audioPlayerContainer,
                    item.role === 'user' && styles.audioPlayerRight,
                  ]}
                >
                  <AudioPlayer
                    audioUrl={item.audioUrl}
                    duration={item.audioDuration}
                    autoPlay={item.role === 'assistant' && autoPlay}
                  />
                </View>
              )}
            </View>
          )}
          contentContainerStyle={styles.messageList}
          showsVerticalScrollIndicator={false}
          onContentSizeChange={() => flatListRef.current?.scrollToEnd()}
        />

        {/* æ‰“å­—æŒ‡ç¤ºå™¨ */}
        {typing && (
          <View style={styles.typingIndicator}>
            <Text style={styles.typingText}>å¯¹æ–¹æ­£åœ¨è¾“å…¥...</Text>
          </View>
        )}

        {/* è¾“å…¥åŒºåŸŸ */}
        {mode === 'text' ? (
          <View style={styles.inputContainer}>
            <TextInput
              style={styles.input}
              placeholder="è¾“å…¥æ¶ˆæ¯..."
              value={inputText}
              onChangeText={setInputText}
              multiline
              maxLength={500}
              editable={!typing}
            />

            <TouchableOpacity
              style={[
                styles.sendButton,
                (!inputText.trim() || typing) && styles.sendButtonDisabled,
              ]}
              onPress={handleSendText}
              disabled={!inputText.trim() || typing}
            >
              <Text style={styles.sendButtonText}>å‘é€</Text>
            </TouchableOpacity>
          </View>
        ) : (
          <VoiceButton onTranscript={handleVoiceTranscript} disabled={typing} />
        )}
      </KeyboardAvoidingView>
    </SafeAreaView>
  );
};

const styles = StyleSheet.create({
  container: {
    flex: 1,
    backgroundColor: Colors.light.background,
  },

  keyboardView: {
    flex: 1,
  },

  messageList: {
    paddingVertical: Spacing.md,
  },

  audioPlayerContainer: {
    paddingHorizontal: Spacing.md,
    marginBottom: Spacing.xs,
  },

  audioPlayerRight: {
    alignItems: 'flex-end',
  },

  typingIndicator: {
    paddingHorizontal: Spacing.md,
    paddingVertical: Spacing.xs,
  },

  typingText: {
    fontSize: FontSizes.sm,
    color: Colors.light.textSecondary,
    fontStyle: 'italic',
  },

  inputContainer: {
    flexDirection: 'row',
    alignItems: 'flex-end',
    padding: Spacing.md,
    backgroundColor: Colors.light.surface,
    borderTopWidth: 1,
    borderTopColor: Colors.light.border,
  },

  input: {
    flex: 1,
    backgroundColor: Colors.light.background,
    borderRadius: BorderRadius.lg,
    paddingHorizontal: Spacing.md,
    paddingVertical: Spacing.sm,
    fontSize: FontSizes.md,
    maxHeight: 100,
    marginRight: Spacing.sm,
    borderWidth: 1,
    borderColor: Colors.light.border,
  },

  sendButton: {
    backgroundColor: Colors.light.primary,
    borderRadius: BorderRadius.lg,
    paddingHorizontal: Spacing.lg,
    paddingVertical: Spacing.md,
    justifyContent: 'center',
    alignItems: 'center',
  },

  sendButtonDisabled: {
    opacity: 0.5,
  },

  sendButtonText: {
    color: '#fff',
    fontSize: FontSizes.md,
    fontWeight: '600',
  },

  modeButton: {
    marginRight: Spacing.md,
  },

  modeButtonText: {
    fontSize: 24,
  },
});

export default ChatScreen;
